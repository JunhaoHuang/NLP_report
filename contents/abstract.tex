\begin{abstract}
	Multi-Label text classification (MTC) is a well-known NLP task that can be applied in many fields, for example, news annotation, web page tagging, and item categorization. Because of the unequal distribution of datasets, MTC is difficult to get better results. As in the dataset we used in NLP WorkShop5, there are significantly more positive reviews with scores of 4 and 5 than negative reviews with scores of 1, 2 and 3. The imbalance between positive and negative data is a great difficulty for MTC, and the smaller amount of data is called "Conner Cases". In order to solve the Extreme multi-label text classification (XMTC) task, we use a new label tree-based deep learning model for XMTC. First, a multi-label attention mechanism, enabling raw text as input, is used to capture the most relevant part of text to each label. Second, a shallow and wide probabilistic label tree (PLT) is adopted to handle millions of labels, which can improve the performance on "tail labels". 
	% We plan to test the performance of this method over six benchmark datasets, including Amazon-3M with around 3 million labels.
\end{abstract}

\begin{IEEEkeywords}
Text classification, NLP, deep learning, multi-label.
\end{IEEEkeywords}