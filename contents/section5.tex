%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions} \label{sec:conclusions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this project, we constructed a generative cooperative network for XMC tasks. The project is inspired by the prior work, namely LightXML. LightXML uses pre-training language model,  transformer, and dynamic negative label sampling. Our LightAttention framework utilize Generative Cooperative Network (GCN) to solve the negative sample problems  by label generator, discriminator. The label generator aims to  generates negative labels and feeds the the negative samples to the discriminator to learn the difference.Then, the discriminator can achieve better label representation with the help of large dynamic negative samples. Compared with LightXML, LightAttention improves accuracy in EUR-Lex. In addtion, the model complexity and training time are less than the LightXML. Furthermore, the lightAttention architecture can be tested on more datasets, like Amazon-670K and Wiki-500K. 